# -*- coding: utf-8 -*-
"""DIODesafioETL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SN1IHvXgxI8qFoxnJt5pPEy6It6l74dX

Entendendo o Desafio

Agora √© a sua hora de brilhar e construir um perfil de destaque na DIO! Explore todos os conceitos explorados at√© aqui e replique (ou melhore, porque n√£o?) este projeto pr√°tico. Para isso, crie seu pr√≥prio reposit√≥rio e aumente ainda mais seu portf√≥lio de projetos no GitHub, o qual pode fazer toda diferen√ßa em suas entrevistas t√©cnicas üòé

Voc√™s j√° mergulharam a fundo no mundo da Ci√™ncia de Dados conosco! Juntos, constru√≠mos um pipeline ETL eficaz, come√ßando com a simples extra√ß√£o de IDs de usu√°rios de uma planilha, seguindo para uma transforma√ß√£o inovadora com a IA do GPT-4 da OpenAI, e culminando no carregamento desses dados transformados de volta ao 'Santander Dev Week 2023'. Agora, o desafio √© reimaginar esse processo de ETL. Como voc√™s aplicariam o que aprenderam em um novo dom√≠nio de aplica√ß√£o, sem depender diretamente de APIs externas (caso queiram simplificar)? Pensem nas infinitas possibilidades e dom√≠nios que podem ser explorados, e deixem a criatividade fluir!
Links √öteis:

[colab.research.google.com (https://colab.research.google.com/drive/1SF_Q3AybFPozCcoFBptDSFbMk-6IVGF-?usp=sharing)]
  :
    Link do Notebook criado via Google Colab com todo o c√≥digo-fonte desenvolvido neste Desafio de Projeto (Lab);

    github.com/digitalinnovationone/santander-dev-week-2023-api:
    
    GitHub com a API desenvolvida para a Santander Dev Week 2023 com informa√ß√µes √∫teis
    (incluindo o link do Swagger e dados importantes sobre a disponibilidade da API).
    Relevante para quem quiser saber mais sobre o processo de cria√ß√£o da API RESTful consumi neste Lab.

Bons estudos üòâ

TO DO
1.  Extrair dados da plan
2.  Analisar os dados para tentar tirar alguma informa√ß√£o importante
2.  Gerar alguma variavel para analise
2.  Gerar um arquivo CSV com o novo dataset
"""

Sdw2023_api_url='https://sdw-2023-prd.up.railway.app'

##Extracao do dados
##Importar o arquivo com os dados dos municipios
import pandas as pd


def trim_all_columns(df):
    """
    Trim whitespace from ends of each value across all series in dataframe
    """
    trim_strings = lambda x: x.strip() if isinstance(x, str) else x
    return df.applymap(trim_strings)


##df = pd.read_csv('SDW2023.csv')
##user_ids = df['UserID'].tolist()
##print(user_ids)
##Leitura do arquivo xls
dfxls = pd.read_excel('IBGE_CIDADES.xls')

dfxls

df_mun_xls = pd.read_excel('RELATORIO_DTB_BRASIL_MUNICIPIO_AJUSTADO.xls')
df_mun_xls['C√≥digo IBGE do Munic√≠pio'] = df_mun_xls['C√≥digo Munic√≠pio Completo'].astype(str).str[:6]
df_mun_xls

# simple example of trimming whitespace from data elements
dfxls = trim_all_columns(dfxls)
df_mun_xls = trim_all_columns(df_mun_xls)

# iterating the columns
#for col in dfxls.columns:
#    print(col)

dfxls['rel_rend_pop_alf'] = dfxls['Valor do rendimento nominal m√©dio mensal dos domic√≠lios particulares permanentes com rendimento domiciliar, por situa√ß√£o do domic√≠lio - Urbana']/dfxls['Popula√ß√£o residente alfabetizada']
dfxls['rel_sus_area_mun'] = dfxls['√Årea da unidade territorial']/dfxls['Estabelecimentos de Sa√∫de SUS']
dfxls['rel_poptot_popocup'] = dfxls['Pessoal ocupado total']/dfxls['Popula√ß√£o residente']
dfxls['rel_poptot_popalfab'] = dfxls['Popula√ß√£o residente alfabetizada']/dfxls['Popula√ß√£o residente']
dfxls['C√≥digo IBGE do Munic√≠pio'] = pd.to_numeric(dfxls['C√≥digo IBGE do Munic√≠pio'])
dfxls
df_ordenado = dfxls.sort_values(by='√çndice de Desenvolvimento Humano Municipal - 2010 (IDHM 2010)', ascending=False)
df_ordenado

df_ordenado.loc[:, ['C√≥digo IBGE do Munic√≠pio', 'C√≥digo da Unidade da Federa√ß√£o','Sigla da Unidade da Federa√ß√£o','C√≥digo IBGE do Munic√≠pio', '√Årea da unidade territorial','Estabelecimentos de Sa√∫de SUS', 'rel_rend_pop_alf','rel_sus_area_mun','√çndice de Desenvolvimento Humano Municipal - 2010 (IDHM 2010)','rel_poptot_popocup','rel_poptot_popalfab']]

dfxls.set_index('C√≥digo IBGE do Munic√≠pio')

df_mun_xls['C√≥digo IBGE do Munic√≠pio'] = pd.to_numeric(df_mun_xls['C√≥digo IBGE do Munic√≠pio'])
df_mun_xls.set_index('C√≥digo IBGE do Munic√≠pio')

## Join para conseguir o nome do municipio
inner_joined_total = dfxls.join(
df_mun_xls.set_index(['C√≥digo IBGE do Munic√≠pio']),
on=['C√≥digo IBGE do Munic√≠pio'],
how="inner",
lsuffix="_x",
rsuffix="_y",
 )





inner_joined_total = inner_joined_total.loc[:, ['C√≥digo IBGE do Munic√≠pio','Nome_Munic√≠pio' ,'C√≥digo da Unidade da Federa√ß√£o','Sigla da Unidade da Federa√ß√£o','√Årea da unidade territorial','Estabelecimentos de Sa√∫de SUS', 'rel_rend_pop_alf','rel_sus_area_mun','√çndice de Desenvolvimento Humano Municipal - 2010 (IDHM 2010)','rel_poptot_popocup','rel_poptot_popalfab']]
inner_joined_total = inner_joined_total.sort_values(by='√çndice de Desenvolvimento Humano Municipal - 2010 (IDHM 2010)', ascending=False)
inner_joined_total

##Transformacao - Usando a API do OPENAI GTP-4
!pip install openai

openai_api_key = 'ADICIONAR A KEY'

import openai
openai.api_key = openai_api_key ## Atribuindo a chave

def generete_ai_news(municipio):
  completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system",
     "content": "Voc√™ √© um especialista em qualidade de vida E IDH."},

    {"role": "user",
     "content": f"Crie uma mensagem com medidas necess√°rias para o prefeito do munic√≠pio {municipio['Nome_Munic√≠pio']} sobre a import√¢ncia da alfabetiza√ß√£o de acordo com o IDH informado pelo muni {municipio['√çndice de Desenvolvimento Humano Municipal - 2010 (IDHM 2010)']} da cidade (m√°ximo de 100 caracteres)"
    }
    ]
  )
  return completion.choices[0].message.content.strip('\"')

### Compreensao de listas
inner_joined_totalLista = [mun for inner_joined_total['C√≥digo IBGE do Munic√≠pio'] in inner_joined_total if (mun := inner_joined_total[:]) is not None ]
#inner_joined_totalLista

for muni in inner_joined_totalLista:
  print(muni)
  news = generete_ai_news(muni)
  print(news)
  ##user['news'].append( "description": news)

##LOAD - CARREGAMENTO
###
inner_joined_total.to_csv('IndicesMunicipios.csv',  encoding='utf-8',index=False)



